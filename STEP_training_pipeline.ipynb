{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run STEP, steps are similar as explained here: https://github.com/zezhishao/STEP\n",
        "\n",
        "However, lot's of installations has to be done first, that are not listed in the git readme"
      ],
      "metadata": {
        "id": "hV7oVeaVaISw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BZPdBrYhXt-2",
        "outputId": "54677768-8019-4862-bbfa-0c4aa568770c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Should output '/content'"
      ],
      "metadata": {
        "id": "WVWww6ImYDCd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWXY9JJNYKLF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zezhishao/STEP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCL-_2suYGRM",
        "outputId": "03968085-d69a-416d-cc60-0023fda246f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'STEP'...\n",
            "remote: Enumerating objects: 765, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 765 (delta 94), reused 83 (delta 83), pack-reused 646\u001b[K\n",
            "Receiving objects: 100% (765/765), 62.56 MiB | 3.73 MiB/s, done.\n",
            "Resolving deltas: 100% (365/365), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you now open the left window and press the folder, you should see STEP"
      ],
      "metadata": {
        "id": "FprGWo5_YTJe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd STEP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uefwVYX8YM9T",
        "outputId": "2fda5d20-942d-4cd6-b1d7-ebe78018bcc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STEP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Should output /content/STEP"
      ],
      "metadata": {
        "id": "gUsTh1uxYZ0K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiePz0zYYc1D",
        "outputId": "38d81600-d335-4361-99da-0f99f7067a67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to do installations. First we need python 3.8, then we need torch and the rest of the reqyurements"
      ],
      "metadata": {
        "id": "zkmGCgPeZlnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If your python version is not 3.8, run the code below. I think 3.9 might also work, but 3.10 doesn't definitely because incompatibability with a specific torch version which we need to use to avoid a dimension error"
      ],
      "metadata": {
        "id": "fwFgeaxfYnXg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --config python3\n",
        "!python --version\n",
        "!sudo apt-get install python3.8-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkDJI6hwY1So",
        "outputId": "4bfed27f-ed22-4daa-c547-324eee685b01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.2 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,520 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,498 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,248 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,244 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,015 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,467 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,152 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.5 kB]\n",
            "Fetched 11.8 MB in 2s (5,010 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 5,098 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.18-1+jammy1 [794 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.18-1+jammy1 [2,024 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.18-1+jammy1 [1,815 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.18-1+jammy1 [438 kB]\n",
            "Fetched 5,098 kB in 2s (2,762 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 120880 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.18-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.18-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.18-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.18-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.18-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.18-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.18-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.18-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.18-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.18-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.18-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.18-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.8\n",
            "Nothing to configure.\n",
            "Python 3.8.18\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.18-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.18-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 1s (245 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 121531 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.18-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.18-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.18-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.18-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.18-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.18-1+jammy1) ...\n",
            "--2023-11-28 01:31:38--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2632263 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.51M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-11-28 01:31:38 (62.7 MB/s) - ‘get-pip.py’ saved [2632263/2632263]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.0.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-23.3.1 setuptools-69.0.2 wheel-0.42.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "# Should now be 3.8.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImLyAKqRZKCY",
        "outputId": "db2fa6e2-5391-4f78-9b26-4cc2aeab5c3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install torch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lPUM1agZNB4",
        "outputId": "6174dd78-0775-4382-8e7a-64055c7ed7c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.2/torch-1.10.0%2Brocm4.2-cp38-cp38-linux_x86_64.whl (1007.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 GB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.2/torchvision-0.11.0%2Brocm4.2-cp38-cp38-linux_x86_64.whl (66.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp38-cp38-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from torch==1.10.0)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy (from torchvision==0.11.0)\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting pillow!=8.3.0,>=5.3.0 (from torchvision==0.11.0)\n",
            "  Downloading Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: typing-extensions, pillow, numpy, torch, torchvision, torchaudio\n",
            "Successfully installed numpy-1.24.4 pillow-10.1.0 torch-1.10.0+rocm4.2 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+rocm4.2 typing-extensions-4.8.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKxbGdZZnkQf",
        "outputId": "4d744f3e-57e0-4e08-b7b7-66047a535b17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp38-cp38-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 GB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp38-cp38-linux_x86_64.whl (21.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio==0.10.0 in /usr/local/lib/python3.8/dist-packages (0.10.0+rocm4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.0+cu111) (1.22.3)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.0+cu111) (9.1.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+rocm4.2\n",
            "    Uninstalling torch-1.10.0+rocm4.2:\n",
            "      Successfully uninstalled torch-1.10.0+rocm4.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.0+rocm4.2\n",
            "    Uninstalling torchvision-0.11.0+rocm4.2:\n",
            "      Successfully uninstalled torchvision-0.11.0+rocm4.2\n",
            "Successfully installed torch-1.10.0+cu111 torchvision-0.11.0+cu111\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lko4m9TZhSy",
        "outputId": "e53ce635-2ea9-43ad-9aba-4f7b65b90a0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==1.0.0 (from -r requirements.txt (line 1))\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools==4.2.4 (from -r requirements.txt (line 2))\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting certifi==2021.10.8 (from -r requirements.txt (line 3))\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==2.0.12 (from -r requirements.txt (line 4))\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting easy-torch==1.2.10 (from -r requirements.txt (line 5))\n",
            "  Downloading easy_torch-1.2.10-py3-none-any.whl (39 kB)\n",
            "Collecting easydict==1.9 (from -r requirements.txt (line 6))\n",
            "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-auth==2.6.6 (from -r requirements.txt (line 7))\n",
            "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.6 (from -r requirements.txt (line 8))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting grpcio==1.46.1 (from -r requirements.txt (line 9))\n",
            "  Downloading grpcio-1.46.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.3 (from -r requirements.txt (line 10))\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata==4.11.3 (from -r requirements.txt (line 11))\n",
            "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
            "Collecting setuptools==59.5.0 (from -r requirements.txt (line 12))\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib==1.1.0 (from -r requirements.txt (line 13))\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Markdown==3.3.7 (from -r requirements.txt (line 14))\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.22.3 (from -r requirements.txt (line 15))\n",
            "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib==3.2.0 (from -r requirements.txt (line 16))\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.1.0 (from -r requirements.txt (line 17))\n",
            "  Downloading Pillow-9.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.1 (from -r requirements.txt (line 18))\n",
            "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1==0.4.8 (from -r requirements.txt (line 19))\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules==0.2.8 (from -r requirements.txt (line 20))\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.27.1 (from -r requirements.txt (line 21))\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib==1.3.1 (from -r requirements.txt (line 22))\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting rsa==4.8 (from -r requirements.txt (line 23))\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting scikit-learn==1.1.1 (from -r requirements.txt (line 24))\n",
            "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.8.0 (from -r requirements.txt (line 25))\n",
            "  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle==1.2.3 (from -r requirements.txt (line 26))\n",
            "  Downloading setproctitle-1.2.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 27)) (1.16.0)\n",
            "Collecting tensorboard==2.9.0 (from -r requirements.txt (line 28))\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server==0.6.1 (from -r requirements.txt (line 29))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit==1.8.1 (from -r requirements.txt (line 30))\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl==3.1.0 (from -r requirements.txt (line 31))\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting tqdm==4.64.0 (from -r requirements.txt (line 32))\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.2.0 (from -r requirements.txt (line 33))\n",
            "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting urllib3==1.26.9 (from -r requirements.txt (line 34))\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Werkzeug==2.1.2 (from -r requirements.txt (line 35))\n",
            "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zipp==3.8.0 (from -r requirements.txt (line 36))\n",
            "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
            "Collecting timm==0.6.7 (from -r requirements.txt (line 37))\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from easy-torch==1.2.10->-r requirements.txt (line 5)) (1.10.0+rocm4.2)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from easy-torch==1.2.10->-r requirements.txt (line 5)) (0.11.0+rocm4.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.9.0->-r requirements.txt (line 28)) (0.42.0)\n",
            "Building wheels for collected packages: easydict\n",
            "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6344 sha256=3dd8f38e956d08ae5b3d6e7e0d889a7d10801b47a82c001b054c459fceeef118\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/e0/e9/305e348717e399665119bd012510d51ff4f22d709ff60c3096\n",
            "Successfully built easydict\n",
            "Installing collected packages: tensorboard-plugin-wit, pyasn1, easydict, certifi, zipp, Werkzeug, urllib3, typing_extensions, tqdm, threadpoolctl, tensorboard-data-server, setuptools, setproctitle, rsa, pyasn1-modules, protobuf, Pillow, oauthlib, numpy, joblib, idna, grpcio, charset-normalizer, cachetools, absl-py, scipy, requests, importlib-metadata, google-auth, scikit-learn, requests-oauthlib, Markdown, timm, google-auth-oauthlib, tensorboard, easy-torch\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 69.0.2\n",
            "    Uninstalling setuptools-69.0.2:\n",
            "      Successfully uninstalled setuptools-69.0.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 10.1.0\n",
            "    Uninstalling Pillow-10.1.0:\n",
            "      Successfully uninstalled Pillow-10.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "Successfully installed Markdown-3.3.7 Pillow-9.1.0 Werkzeug-2.1.2 absl-py-1.0.0 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.12 easy-torch-1.2.10 easydict-1.9 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.1 idna-3.3 importlib-metadata-4.11.3 joblib-1.1.0 numpy-1.22.3 oauthlib-3.2.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 scikit-learn-1.1.1 scipy-1.8.0 setproctitle-1.2.3 setuptools-59.5.0 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 timm-0.6.7 tqdm-4.64.0 typing_extensions-4.2.0 urllib3-1.26.9 zipp-3.8.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow[and-cuda]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__SYmxa9k0JQ",
        "outputId": "d9fb4874-d8b5-49d1-8b1c-81659de50f09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow[and-cuda]\n",
            "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.0.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow[and-cuda])\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers>=23.1.21 (from tensorflow[and-cuda])\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow[and-cuda])\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow[and-cuda])\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.46.1)\n",
            "Collecting h5py>=2.9.0 (from tensorflow[and-cuda])\n",
            "  Downloading h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow[and-cuda])\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow[and-cuda])\n",
            "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.22.3)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow[and-cuda])\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (23.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow[and-cuda])\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (59.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow[and-cuda])\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow[and-cuda])\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow[and-cuda])\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (4.2.0)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow[and-cuda])\n",
            "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow[and-cuda])\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.42.0)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow[and-cuda])\n",
            "  Downloading grpcio-1.59.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.6.6)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (4.8)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
            "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (4.11.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.2.0)\n",
            "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Downloading h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.59.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, keras, h5py, grpcio, google-pasta, gast, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.1\n",
            "    Uninstalling protobuf-3.20.1:\n",
            "      Successfully uninstalled protobuf-3.20.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.6.6\n",
            "    Uninstalling google-auth-2.6.6:\n",
            "      Successfully uninstalled google-auth-2.6.6\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.0\n",
            "    Uninstalling tensorboard-2.9.0:\n",
            "      Successfully uninstalled tensorboard-2.9.0\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.4 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.3 h5py-3.10.0 keras-2.13.1 libclang-16.0.6 opt-einsum-3.3.0 protobuf-4.25.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 wrapt-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For some reason pandas isn't installed\n",
        "!pip install pandas\n",
        "#Restart runtime if prompted"
      ],
      "metadata": {
        "id": "jpFABvOob6v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSB_FIKwfhPS",
        "outputId": "ec948b6c-62ec-43c4-d423-d8eca916181e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytables (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytables\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tables\n",
            "  Downloading tables-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cython>=0.29.21 (from tables)\n",
            "  Downloading Cython-3.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from tables) (1.22.3)\n",
            "Collecting numexpr>=2.6.2 (from tables)\n",
            "  Downloading numexpr-2.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting blosc2~=2.0.0 (from tables)\n",
            "  Downloading blosc2-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging (from tables)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting py-cpuinfo (from tables)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting msgpack (from blosc2~=2.0.0->tables)\n",
            "  Downloading msgpack-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Downloading Cython-3.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numexpr-2.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (534 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m534.8/534.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-cpuinfo, packaging, numexpr, msgpack, cython, blosc2, tables\n",
            "Successfully installed blosc2-2.0.0 cython-3.0.6 msgpack-1.0.7 numexpr-2.8.6 packaging-23.2 py-cpuinfo-9.0.0 tables-3.8.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the data\n",
        "#### First we need to manually upload the zip file which can be downloaded at https://drive.google.com/file/d/1PY7IZ3SchpyXfNIXs71A2GEV29W5QCv2/view?usp=sharing"
      ],
      "metadata": {
        "id": "-HCrQgtQZ7Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the folder in the left tree, go to STEP -> datasets and drag the raw zipfile into it (might take some time to upload). then unzip using the code below"
      ],
      "metadata": {
        "id": "v7AelnhZaiUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/STEP/datasets/raw_data.zip -d /content/STEP/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_8DOvdXZ6H-",
        "outputId": "849a22f6-16b4-4538-8b99-f3acdb34c3fa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/STEP/datasets/raw_data.zip\n",
            "   creating: /content/STEP/datasets/raw_data/\n",
            "   creating: /content/STEP/datasets/raw_data/METR-LA/\n",
            "  inflating: /content/STEP/datasets/raw_data/METR-LA/adj_METR-LA.pkl  \n",
            "  inflating: /content/STEP/datasets/raw_data/METR-LA/METR-LA.h5  \n",
            "   creating: /content/STEP/datasets/raw_data/PEMS-BAY/\n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS-BAY/adj_PEMS-BAY.pkl  \n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS-BAY/PEMS-BAY.h5  \n",
            "   creating: /content/STEP/datasets/raw_data/PEMS04/\n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS04/adj_PEMS04.pkl  \n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS04/adj_PEMS04_distance.pkl  \n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS04/PEMS04.csv  \n",
            "  inflating: /content/STEP/datasets/raw_data/PEMS04/PEMS04.npz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the data by running\n",
        "!bash scripts/data_preparation/all.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jufuVqn0bIGg",
        "outputId": "80b4191f-8f7f-4bc5-91bc-4197268a3f44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/METR-LA/METR-LA.h5         |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/METR-LA/adj_METR-LA.pkl    |\n",
            "|     history_seq_len = 12                                           |\n",
            "|          output_dir = datasets/METR-LA                             |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.7                                          |\n",
            "|         valid_ratio = 0.1                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (34272, 207, 1)\n",
            "number of training samples:23974\n",
            "number of validation samples:3425\n",
            "number of test samples:6850\n",
            "mean (training data): 54.40552365611337\n",
            "std (training data): 19.494882160412384\n",
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/METR-LA/METR-LA.h5         |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/METR-LA/adj_METR-LA.pkl    |\n",
            "|     history_seq_len = 2016                                         |\n",
            "|          output_dir = datasets/METR-LA                             |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.7                                          |\n",
            "|         valid_ratio = 0.1                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (34272, 207, 1)\n",
            "number of training samples:21970\n",
            "number of validation samples:3425\n",
            "number of test samples:6850\n",
            "mean (training data): 54.40552365611337\n",
            "std (training data): 19.494882160412384\n",
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/PEMS-BAY/PEMS-BAY.h5       |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/PEMS-BAY/adj_PEMS-BAY.pkl  |\n",
            "|     history_seq_len = 12                                           |\n",
            "|          output_dir = datasets/PEMS-BAY                            |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.7                                          |\n",
            "|         valid_ratio = 0.1                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (52116, 325, 1)\n",
            "number of training samples:36465\n",
            "number of validation samples:5209\n",
            "number of test samples:10419\n",
            "mean (training data): 62.73669922477996\n",
            "std (training data): 9.43724126602455\n",
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/PEMS-BAY/PEMS-BAY.h5       |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/PEMS-BAY/adj_PEMS-BAY.pkl  |\n",
            "|     history_seq_len = 2016                                         |\n",
            "|          output_dir = datasets/PEMS-BAY                            |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.7                                          |\n",
            "|         valid_ratio = 0.1                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (52116, 325, 1)\n",
            "number of training samples:34461\n",
            "number of validation samples:5209\n",
            "number of test samples:10419\n",
            "mean (training data): 62.73669922477996\n",
            "std (training data): 9.43724126602455\n",
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/PEMS04/PEMS04.npz          |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/PEMS04/adj_PEMS04.pkl      |\n",
            "|     history_seq_len = 12                                           |\n",
            "|          output_dir = datasets/PEMS04                              |\n",
            "|       steps_per_day = 288                                          |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.6                                          |\n",
            "|         valid_ratio = 0.2                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (16992, 307, 1)\n",
            "number of training samples:10181\n",
            "number of validation samples:3394\n",
            "number of test samples:3394\n",
            "mean (training data): 207.21009963744956\n",
            "std (training data): 156.48002643540894\n",
            "----------------------------------------------------------------------\n",
            "|      data_file_path = datasets/raw_data/PEMS04/PEMS04.npz          |\n",
            "|                 dow = True                                         |\n",
            "|      future_seq_len = 12                                           |\n",
            "|     graph_file_path = datasets/raw_data/PEMS04/adj_PEMS04.pkl      |\n",
            "|     history_seq_len = 4032                                         |\n",
            "|          output_dir = datasets/PEMS04                              |\n",
            "|       steps_per_day = 288                                          |\n",
            "|      target_channel = [0]                                          |\n",
            "|                 tod = True                                         |\n",
            "|         train_ratio = 0.6                                          |\n",
            "|         valid_ratio = 0.2                                          |\n",
            "----------------------------------------------------------------------\n",
            "raw time series shape: (16992, 307, 1)\n",
            "number of training samples:6161\n",
            "number of validation samples:3394\n",
            "number of test samples:3394\n",
            "mean (training data): 207.21009963744956\n",
            "std (training data): 156.48002643540894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUNNING THE MODEL (BELOW):\n",
        "\n",
        "Replace `$DATASET_NAME` with one of `METR-LA`, `PEMS-BAY`, `PEMS04` as shown in the code above. Configuration file `step/STEP_$DATASET.py` describes the forecasting configurations. Edit BATCH_SIZE (if you get cude out of memory) and GPU_NUM (set = 0 if using colab GPU) in the configuration file and --gpu in the command line to run on your own hardware. Note that different GPU number leads to different real batch sizes, affecting the learning rate setting and the forecasting accuracy.\n",
        "\n",
        "Our training logs are shown in training_logs/STEP_METR-LA.log, training_logs/STEP_METR-LA.log and training_logs/STEP_PEMS-BAY.log."
      ],
      "metadata": {
        "id": "SSag3Mn8gCo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTANT\n",
        "If running on one gpu, you need to go to the step/STEP_$DATASET.py file by double clicking on it in the file tree and change NUM_GPU from 2 to 1 on line 30."
      ],
      "metadata": {
        "id": "NKYMFtEIhGNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python step/run.py --cfg='step/STEP_$DATASET.py' --gpus='0, 1'\n",
        "# python step/run.py --cfg='step/STEP_METR-LA.py' --gpus='0, 1'\n",
        "# python step/run.py --cfg='step/STEP_PEMS-BAY.py' --gpus='0, 1'\n",
        "# python step/run.py --cfg='step/STEP_PEMS04.py' --gpus='0, 1'\n",
        "!python step/run.py --cfg='step/STEP_PEMS04.py' --gpus=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGyCbW-IbLi2",
        "outputId": "82d24157-ad85-4d46-c0c8-46ee6ddbb356"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-28 01:58:25,884 - easytorch-launcher - INFO - Launching EasyTorch training.\n",
            "DESCRIPTION: STEP(PEMS04) configuration\n",
            "RUNNER: <class 'step.step_runner.step_runner.STEPRunner'>\n",
            "DATASET_CLS: <class 'step.step_data.forecasting_dataset.ForecastingDataset'>\n",
            "DATASET_NAME: PEMS04\n",
            "DATASET_TYPE: Traffic flow\n",
            "DATASET_INPUT_LEN: 12\n",
            "DATASET_OUTPUT_LEN: 12\n",
            "DATASET_ARGS:\n",
            "  seq_len: 4032\n",
            "GPU_NUM: 1\n",
            "ENV:\n",
            "  SEED: 0\n",
            "  CUDNN:\n",
            "    ENABLED: True\n",
            "MODEL:\n",
            "  NAME: STEP\n",
            "  ARCH: <class 'step.step_arch.step.STEP'>\n",
            "  PARAM:\n",
            "    dataset_name: PEMS04\n",
            "    pre_trained_tsformer_path: tsformer_ckpt/TSFormer_PEMS04.pt\n",
            "    tsformer_args:\n",
            "      patch_size: 12\n",
            "      in_channel: 1\n",
            "      embed_dim: 96\n",
            "      num_heads: 4\n",
            "      mlp_ratio: 4\n",
            "      dropout: 0.1\n",
            "      num_token: 336.0\n",
            "      mask_ratio: 0.75\n",
            "      encoder_depth: 4\n",
            "      decoder_depth: 1\n",
            "      mode: forecasting\n",
            "    backend_args:\n",
            "      num_nodes: 307\n",
            "      support_len: 2\n",
            "      dropout: 0.3\n",
            "      gcn_bool: True\n",
            "      addaptadj: True\n",
            "      aptinit: None\n",
            "      in_dim: 2\n",
            "      out_dim: 12\n",
            "      residual_channels: 32\n",
            "      dilation_channels: 32\n",
            "      skip_channels: 256\n",
            "      end_channels: 512\n",
            "      kernel_size: 2\n",
            "      blocks: 4\n",
            "      layers: 2\n",
            "    dgl_args:\n",
            "      dataset_name: PEMS04\n",
            "      k: 10\n",
            "      input_seq_len: 12\n",
            "      output_seq_len: 12\n",
            "  FORWARD_FEATURES: [0, 1, 2]\n",
            "  TARGET_FEATURES: [0]\n",
            "  DDP_FIND_UNUSED_PARAMETERS: True\n",
            "TRAIN:\n",
            "  LOSS: step_loss\n",
            "  OPTIM:\n",
            "    TYPE: Adam\n",
            "    PARAM:\n",
            "      lr: 0.002\n",
            "      weight_decay: 1e-05\n",
            "      eps: 1e-08\n",
            "  LR_SCHEDULER:\n",
            "    TYPE: MultiStepLR\n",
            "    PARAM:\n",
            "      milestones: [1, 18, 36, 54, 72]\n",
            "      gamma: 0.5\n",
            "  CLIP_GRAD_PARAM:\n",
            "    max_norm: 3.0\n",
            "  NUM_EPOCHS: 1\n",
            "  CKPT_SAVE_DIR: checkpoints/STEP_1\n",
            "  DATA:\n",
            "    DIR: datasets/PEMS04\n",
            "    BATCH_SIZE: 8\n",
            "    PREFETCH: False\n",
            "    SHUFFLE: True\n",
            "    NUM_WORKERS: 2\n",
            "    PIN_MEMORY: True\n",
            "  NULL_VAL: 0.0\n",
            "VAL:\n",
            "  INTERVAL: 1\n",
            "  DATA:\n",
            "    DIR: datasets/PEMS04\n",
            "    BATCH_SIZE: 8\n",
            "    PREFETCH: False\n",
            "    SHUFFLE: False\n",
            "    NUM_WORKERS: 2\n",
            "    PIN_MEMORY: True\n",
            "TEST:\n",
            "  INTERVAL: 1\n",
            "  DATA:\n",
            "    DIR: datasets/PEMS04\n",
            "    BATCH_SIZE: 8\n",
            "    PREFETCH: False\n",
            "    SHUFFLE: False\n",
            "    NUM_WORKERS: 2\n",
            "    PIN_MEMORY: True\n",
            "\n",
            "2023-11-28 01:58:26,141 - easytorch-env - INFO - Use GPUs 0.\n",
            "2023-11-28 01:58:26,147 - easytorch-launcher - INFO - Initializing runner \"<class 'step.step_runner.step_runner.STEPRunner'>\"\n",
            "2023-11-28 01:58:26,147 - easytorch-env - INFO - Disable TF32 mode\n",
            "2023-11-28 01:58:26,148 - easytorch - INFO - Set ckpt save dir: 'checkpoints/STEP_1/4b7e8eb7b4c86bf9c769bc952006d9a0'\n",
            "2023-11-28 01:58:26,149 - easytorch - INFO - Building model.\n",
            "2023-11-28 01:58:30,681 - easytorch-training - INFO - Initializing training.\n",
            "2023-11-28 01:58:30,681 - easytorch-training - INFO - Set clip grad, param: {'max_norm': 3.0}\n",
            "2023-11-28 01:58:30,681 - easytorch-training - INFO - Building training data loader.\n",
            "train len: 10181\n",
            "2023-11-28 01:58:30,784 - easytorch-training - INFO - Set optim: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.002\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "2023-11-28 01:58:30,784 - easytorch-training - INFO - Set lr_scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7df5be47ba60>\n",
            "2023-11-28 01:58:31.856516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-28 01:58:32,528 - easytorch-training - INFO - Initializing validation.\n",
            "2023-11-28 01:58:32,528 - easytorch-training - INFO - Building val data loader.\n",
            "val len: 3394\n",
            "test len: 3394\n",
            "2023-11-28 01:58:32,736 - easytorch-training - INFO - Epoch 1 / 1\n",
            "100% 1273/1273 [14:24<00:00,  1.47it/s]\n",
            "2023-11-28 02:12:56,756 - easytorch-training - INFO - Result <train>: [train_time: 864.02 (s), lr: 2.00e-03, train_MAE: 25.8038, train_RMSE: 38.3354, train_MAPE: 0.2518]\n",
            "2023-11-28 02:12:56,757 - easytorch-training - INFO - Start validation.\n",
            "100% 425/425 [03:33<00:00,  1.99it/s]\n",
            "2023-11-28 02:16:30,141 - easytorch-training - INFO - Result <val>: [val_time: 213.38 (s), val_MAE: 20.5594, val_RMSE: 30.6537, val_MAPE: 0.1570]\n",
            "2023-11-28 02:16:30,815 - easytorch-training - INFO - Checkpoint checkpoints/STEP_1/4b7e8eb7b4c86bf9c769bc952006d9a0/STEP_best_val_MAE.pt saved\n",
            "2023-11-28 02:20:03,192 - easytorch-training - INFO - Evaluate best model on test data for horizon 1, Test MAE: 18.2632, Test RMSE: 28.4454, Test MAPE: 0.1614\n",
            "2023-11-28 02:20:03,197 - easytorch-training - INFO - Evaluate best model on test data for horizon 2, Test MAE: 19.1943, Test RMSE: 30.2714, Test MAPE: 0.1447\n",
            "2023-11-28 02:20:03,202 - easytorch-training - INFO - Evaluate best model on test data for horizon 3, Test MAE: 19.3162, Test RMSE: 30.4245, Test MAPE: 0.1414\n",
            "2023-11-28 02:20:03,206 - easytorch-training - INFO - Evaluate best model on test data for horizon 4, Test MAE: 19.7186, Test RMSE: 30.8285, Test MAPE: 0.1617\n",
            "2023-11-28 02:20:03,211 - easytorch-training - INFO - Evaluate best model on test data for horizon 5, Test MAE: 20.0768, Test RMSE: 31.2960, Test MAPE: 0.1571\n",
            "2023-11-28 02:20:03,216 - easytorch-training - INFO - Evaluate best model on test data for horizon 6, Test MAE: 20.4583, Test RMSE: 31.6351, Test MAPE: 0.1735\n",
            "2023-11-28 02:20:03,221 - easytorch-training - INFO - Evaluate best model on test data for horizon 7, Test MAE: 20.4366, Test RMSE: 31.7663, Test MAPE: 0.1629\n",
            "2023-11-28 02:20:03,226 - easytorch-training - INFO - Evaluate best model on test data for horizon 8, Test MAE: 20.6003, Test RMSE: 32.0956, Test MAPE: 0.1585\n",
            "2023-11-28 02:20:03,230 - easytorch-training - INFO - Evaluate best model on test data for horizon 9, Test MAE: 20.9501, Test RMSE: 32.4659, Test MAPE: 0.1505\n",
            "2023-11-28 02:20:03,235 - easytorch-training - INFO - Evaluate best model on test data for horizon 10, Test MAE: 21.2439, Test RMSE: 32.8636, Test MAPE: 0.1535\n",
            "2023-11-28 02:20:03,240 - easytorch-training - INFO - Evaluate best model on test data for horizon 11, Test MAE: 21.9781, Test RMSE: 33.7582, Test MAPE: 0.1568\n",
            "2023-11-28 02:20:03,245 - easytorch-training - INFO - Evaluate best model on test data for horizon 12, Test MAE: 22.6966, Test RMSE: 34.7040, Test MAPE: 0.1621\n",
            "2023-11-28 02:20:03,329 - easytorch-training - INFO - Result <test>: [test_time: 212.51 (s), test_MAE: 20.4111, test_RMSE: 31.7530, test_MAPE: 0.1570]\n",
            "2023-11-28 02:20:04,004 - easytorch-training - INFO - Checkpoint checkpoints/STEP_1/4b7e8eb7b4c86bf9c769bc952006d9a0/STEP_1.pt saved\n",
            "2023-11-28 02:20:04,005 - easytorch-training - INFO - The training finished at 2023-11-28 02:20:04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBVmwXXhhZwr",
        "outputId": "620feeb9-3032-41c4-f2f7-bceb252b4411"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To analyse gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyKlNSA3ouIG",
        "outputId": "24d1790f-d79a-4124-d421-a15628ab834e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 28 01:55:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    38W / 300W |   1088MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IF YOU GET SOME WIERD ASS CUDA ERROR, THIS MIGHT SOLVE IT\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "Z1doReXMoRiy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qw4B18t1mZT0",
        "outputId": "3a12725a-beea-4a12-94e9-80edd835d2f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qk259Lm5oCO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}